<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Case-Based Off-Policy Evaluation Using Prototype Learning | Healthy AI Lab</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Case-Based Off-Policy Evaluation Using Prototype Learning" />
<meta name="author" content="Anton Matsson, Fredrik Johansson" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Estimating the behavior policy for off-policy evaluation using prototypes allows us to describe differences between policies and their estimated values" />
<meta property="og:description" content="Estimating the behavior policy for off-policy evaluation using prototypes allows us to describe differences between policies and their estimated values" />
<link rel="canonical" href="http://localhost:4000/blog/2022/07/27/cbope.html" />
<meta property="og:url" content="http://localhost:4000/blog/2022/07/27/cbope.html" />
<meta property="og:site_name" content="Healthy AI Lab" />
<meta property="og:image" content="http://localhost:4000/assets/posts/cbope.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-07-27T10:00:00+02:00" />
<script type="application/ld+json">
{"datePublished":"2022-07-27T10:00:00+02:00","headline":"Case-Based Off-Policy Evaluation Using Prototype Learning","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/blog/2022/07/27/cbope.html"},"url":"http://localhost:4000/blog/2022/07/27/cbope.html","author":{"@type":"Person","name":"Anton Matsson, Fredrik Johansson"},"image":"http://localhost:4000/assets/posts/cbope.png","description":"Estimating the behavior policy for off-policy evaluation using prototypes allows us to describe differences between policies and their estimated values","@type":"BlogPosting","dateModified":"2022-07-27T10:00:00+02:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Healthy AI Lab" /></head>
<body><header class="site-header" role="banner">
  <div class="wrapper"><div class="site-title">
      <a rel="author" href="/">Healthy AI Lab<br/></a>
      <div class="site-subtitle">at Chalmers University of Technology</div>
    </div>

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
      <label for="nav-trigger">
        <span class="menu-icon">
          <svg viewBox="0 0 18 15" width="18px" height="15px">
            <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
          </svg>
        </span>
      </label>

      <div class="trigger"><a class="page-link" href="/about/">About</a><a class="page-link" href="/code/">Code &amp; data</a><a class="page-link" href="/news/">News</a><a class="page-link" href="/people/">People</a></div>
    </nav>

  </div>
</header>
<main class="page-content" aria-label="Content">    
      


<div class="wrapper">
  <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

    <header class="post-header">
      <h1 class="post-title p-name" itemprop="name headline">Case-Based Off-Policy Evaluation Using Prototype Learning</h1><p>
          <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span class="p-author h-card" itemprop="name">Anton Matsson, Fredrik Johansson</span></span>
        </p>
        <p><span class="p-venue h-card" itemprop="name">UAI 2022
          
            <a href="https://openreview.net/forum?id=r3EI6UUiqx9" target="_blank">[Paper URL]</a>
          
        </span></p>
      
    </header>


    <div class="post-content e-content" itemprop="articleBody">
      <h2 id="estimating-the-behavior-policy-for-off-policy-evaluation-using-prototypes-allows-us-to-describe-differences-between-policies-and-their-estimated-values">Estimating the behavior policy for off-policy evaluation using prototypes allows us to describe differences between policies and their estimated values</h2>

<p><img src="/assets/posts/cbope.png" alt="Policy evaluation with prototypes" class="post-general-image" /></p>

<p>The increasing amount of available data on medical interventions and reported outcomes creates opportunities to search for new clinical policies. As an example, researchers have employed reinforcement learning algorithms to learn new strategies for the management of sepsis [1]. However, for such a policy to be used in practice, it is of utmost importance that its performance, or value, can be reliably estimated. Ideally, the estimated value of this target policy should be higher than the value of the—often unknown—behavior policy followed by clinicians in the observed data.</p>

<p>While the value of the behavior policy can be easily estimated by averaging outcomes in the observed data, the value of the target policy is fundamentally unknown. Off-policy evaluation (OPE) refers to the problem of estimating the target policy value using data collected under the behavior policy. A standard method for OPE is importance sampling (IS), where each observed outcome is weighted by the probability ratio of taking the actions preceding that outcome under the target policy and the behavior policy, respectively. When the behavior policy is unknown, it must be estimated from data before the IS average can be computed.</p>

<p>Even though importance sampling is a popular method for OPE, it suffers from high variance when there are significant differences between target and behavior policies. By inspecting the IS weights, it is possible to collect individual samples for which the policies differ, but this approach does not describe patterns in differences between polices. To address this problem, we suggest estimating the unknown behavior policy using prototype learning [2], which gives us a set of interpretable prototype cases from the observed data. The prototypes are selected by the learning algorithm, and for a specific input, e.g., a patient, the model estimates the behavior policy by comparing the input to the prototypes in a learned representation. The idea is reminiscent of how physicians use their experience from previous patients when treating new ones.</p>

<p>We use the learned prototypes as a diagnostic tool for OPE. By inspecting the behavior and target policies for each of the prototypes, we obtain a condensed overview of differences between the policies. A domain expert can reason about the validity of the target policy and assess whether the data supports evaluating it using importance sampling. Additionally, we use the prototypes to divide estimated policy values into prototype-based components, allowing us to describe situations when it may be beneficial to follow the target policy instead of the behavior policy, and vice versa.</p>

<p>If you are interested, you are welcome to read our UAI 2022 paper [3], where we elaborate on the prototype idea and demonstrate it using a real-world example of sepsis management.</p>

<ul>
  <li>[1] Matthieu Komorowski et al. The artificial intelligence clinician learns optimal treatment strategies for sepsis in intensive care. Nature Medicine, 24(11): 1716–1720, 2018.</li>
  <li>[2] Yao Ming et al. Interpretable and steerable sequence learning via prototypes. In The 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining, 2019.</li>
  <li>[3] Anton Matsson and Fredrik Johansson. Case-based off-policy evaluation using prototype learning. In The 38th Conference on Uncertainty in Artificial Intelligence, 2022.</li>
</ul>

    </div><a class="u-url" href="/blog/2022/07/27/cbope.html" hidden></a>
    <p class="post-meta">
      <time class="dt-published" datetime="2022-07-27T10:00:00+02:00" itemprop="datePublished">Jul 27, 2022
      </time>
    </p>
  </article>
</div>

    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <!--<h2 class="footer-heading">Healthy AI Lab</h2>-->

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <!---->
        <!--
        <ul class="contact-list"><li>Contact:</li>
          <li><a class="u-email" href="mailto:fredrik.johansson@chalmers.se">fredrik.johansson@chalmers.se</a></li></ul>-->
      </div>

      <div class="footer-col footer-col-2">

      </div>
    </div>

  </div>

</footer>
</body>

</html>
