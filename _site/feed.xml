<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-09-02T12:54:40+02:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Healthy AI Lab</title><subtitle>Healthy AI lab: Research in machine learning and healthcare</subtitle><entry><title type="html">Case-Based Off-Policy Evaluation Using Prototype Learning</title><link href="http://localhost:4000/blog/2022/07/27/cbope.html" rel="alternate" type="text/html" title="Case-Based Off-Policy Evaluation Using Prototype Learning" /><published>2022-07-27T10:00:00+02:00</published><updated>2022-07-27T10:00:00+02:00</updated><id>http://localhost:4000/blog/2022/07/27/cbope</id><content type="html" xml:base="http://localhost:4000/blog/2022/07/27/cbope.html">&lt;h2 id=&quot;estimating-the-behavior-policy-for-off-policy-evaluation-using-prototypes-allows-us-to-describe-differences-between-policies-and-their-estimated-values&quot;&gt;Estimating the behavior policy for off-policy evaluation using prototypes allows us to describe differences between policies and their estimated values&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/cbope.png&quot; alt=&quot;Policy evaluation with prototypes&quot; class=&quot;post-general-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The increasing amount of available data on medical interventions and reported outcomes creates opportunities to search for new clinical policies. As an example, researchers have employed reinforcement learning algorithms to learn new strategies for the management of sepsis [1]. However, for such a policy to be used in practice, it is of utmost importance that its performance, or value, can be reliably estimated. Ideally, the estimated value of this target policy should be higher than the value of the—often unknown—behavior policy followed by clinicians in the observed data.&lt;/p&gt;

&lt;p&gt;While the value of the behavior policy can be easily estimated by averaging outcomes in the observed data, the value of the target policy is fundamentally unknown. Off-policy evaluation (OPE) refers to the problem of estimating the target policy value using data collected under the behavior policy. A standard method for OPE is importance sampling (IS), where each observed outcome is weighted by the probability ratio of taking the actions preceding that outcome under the target policy and the behavior policy, respectively. When the behavior policy is unknown, it must be estimated from data before the IS average can be computed.&lt;/p&gt;

&lt;p&gt;Even though importance sampling is a popular method for OPE, it suffers from high variance when there are significant differences between target and behavior policies. By inspecting the IS weights, it is possible to collect individual samples for which the policies differ, but this approach does not describe patterns in differences between polices. To address this problem, we suggest estimating the unknown behavior policy using prototype learning [2], which gives us a set of interpretable prototype cases from the observed data. The prototypes are selected by the learning algorithm, and for a specific input, e.g., a patient, the model estimates the behavior policy by comparing the input to the prototypes in a learned representation. The idea is reminiscent of how physicians use their experience from previous patients when treating new ones.&lt;/p&gt;

&lt;p&gt;We use the learned prototypes as a diagnostic tool for OPE. By inspecting the behavior and target policies for each of the prototypes, we obtain a condensed overview of differences between the policies. A domain expert can reason about the validity of the target policy and assess whether the data supports evaluating it using importance sampling. Additionally, we use the prototypes to divide estimated policy values into prototype-based components, allowing us to describe situations when it may be beneficial to follow the target policy instead of the behavior policy, and vice versa.&lt;/p&gt;

&lt;p&gt;If you are interested, you are welcome to read our UAI 2022 paper [3], where we elaborate on the prototype idea and demonstrate it using a real-world example of sepsis management.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;[1] Matthieu Komorowski et al. The artificial intelligence clinician learns optimal treatment strategies for sepsis in intensive care. Nature Medicine, 24(11): 1716–1720, 2018.&lt;/li&gt;
  &lt;li&gt;[2] Yao Ming et al. Interpretable and steerable sequence learning via prototypes. In The 25th ACM SIGKDD International Conference on Knowledge Discovery &amp;amp; Data Mining, 2019.&lt;/li&gt;
  &lt;li&gt;[3] Anton Matsson and Fredrik Johansson. Case-based off-policy evaluation using prototype learning. In The 38th Conference on Uncertainty in Artificial Intelligence, 2022.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Anton Matsson, Fredrik Johansson</name></author><category term="blog" /><summary type="html">Estimating the behavior policy for off-policy evaluation using prototypes allows us to describe differences between policies and their estimated values</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/posts/cbope.png" /><media:content medium="image" url="http://localhost:4000/assets/posts/cbope.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Sharing pattern submodels for prediction with missing values</title><link href="http://localhost:4000/blog/2022/06/22/spsm.html" rel="alternate" type="text/html" title="Sharing pattern submodels for prediction with missing values" /><published>2022-06-22T10:00:00+02:00</published><updated>2022-06-22T10:00:00+02:00</updated><id>http://localhost:4000/blog/2022/06/22/spsm</id><content type="html" xml:base="http://localhost:4000/blog/2022/06/22/spsm.html">&lt;h3 id=&quot;abstract&quot;&gt;Abstract&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/SPSM_Example_graphic_final.png&quot; alt=&quot;Illustration of pattern missingness&quot; class=&quot;post-general-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Missing values are unavoidable in many applications of machine learning and present a challenge both during training and at test time. When variables are missing in recurring patterns, fitting separate pattern submodels have been proposed as a solution. However, independent models do not make efficient use of all available data. Conversely, fitting a shared model to the full data set typically relies on imputation which may be suboptimal when missingness depends on unobserved factors. We propose an alternative approach, called sharing pattern submodels, which make predictions that are a) robust to missing values at test time, b) maintains or improves the predictive power of pattern submodels, and c) has a short description enabling improved interpretability. We identify cases where sharing is provably optimal, even when missingness itself is predictive and when the prediction target depends on unobserved variables. Classification and regression experiments on synthetic data and two healthcare data sets demonstrate that our models achieve a favorable trade-off between pattern specialization and information sharing.&lt;/p&gt;</content><author><name>Lena Stempfle, Fredrik Johansson</name></author><category term="blog" /><summary type="html">Abstract</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/posts/SPSM_Example_graphic_final.png" /><media:content medium="image" url="http://localhost:4000/assets/posts/SPSM_Example_graphic_final.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">ADCB: An Alzheimer’s disease simulator for benchmarking observational estimators of causal effects</title><link href="http://localhost:4000/blog/2022/04/07/adcb.html" rel="alternate" type="text/html" title="ADCB: An Alzheimer’s disease simulator for benchmarking observational estimators of causal effects" /><published>2022-04-07T10:00:00+02:00</published><updated>2022-04-07T10:00:00+02:00</updated><id>http://localhost:4000/blog/2022/04/07/adcb</id><content type="html" xml:base="http://localhost:4000/blog/2022/04/07/adcb.html">&lt;h3 id=&quot;abstract&quot;&gt;Abstract&lt;/h3&gt;
&lt;p&gt;Simulators make unique benchmarks for causal effect estimation as they do not rely on unverifiable assumptions or the ability to intervene on real-world systems. This is especially important for estimators targeting healthcare applications as possibilities for experimentation are limited with good reason. We develop a simulator of clinical variables associated with Alzheimer’s disease, aimed to serve as a benchmark for causal effect estimation while modeling intricacies of healthcare data. We fit the system to the Alzheimer’s Disease Neuroimaging Initiative (ADNI) dataset and ground hand-crafted components in results from comparative treatment trials and observational treatment patterns. The simulator includes parameters which alter the nature and difficulty of the causal inference tasks, such as latent variables, effect heterogeneity, length of observed subject history, behavior policy and sample size. We use the simulator to compare standard estimators of average and conditional treatment effects.&lt;/p&gt;</content><author><name>Newton Mwai Kinyanjui, Fredrik D. Johansson</name></author><category term="blog" /><summary type="html">Abstract Simulators make unique benchmarks for causal effect estimation as they do not rely on unverifiable assumptions or the ability to intervene on real-world systems. This is especially important for estimators targeting healthcare applications as possibilities for experimentation are limited with good reason. We develop a simulator of clinical variables associated with Alzheimer’s disease, aimed to serve as a benchmark for causal effect estimation while modeling intricacies of healthcare data. We fit the system to the Alzheimer’s Disease Neuroimaging Initiative (ADNI) dataset and ground hand-crafted components in results from comparative treatment trials and observational treatment patterns. The simulator includes parameters which alter the nature and difficulty of the causal inference tasks, such as latent variables, effect heterogeneity, length of observed subject history, behavior policy and sample size. We use the simulator to compare standard estimators of average and conditional treatment effects.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/posts/causal_graph_color-crop.png" /><media:content medium="image" url="http://localhost:4000/assets/posts/causal_graph_color-crop.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Learning using privileged time series information</title><link href="http://localhost:4000/blog/2022/02/01/lupi-linear.html" rel="alternate" type="text/html" title="Learning using privileged time series information" /><published>2022-02-01T09:00:00+01:00</published><updated>2022-02-01T09:00:00+01:00</updated><id>http://localhost:4000/blog/2022/02/01/lupi-linear</id><content type="html" xml:base="http://localhost:4000/blog/2022/02/01/lupi-linear.html">&lt;h3 id=&quot;abstract&quot;&gt;Abstract&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/lupi_illustration.png&quot; alt=&quot;Policy evaluation with prototypes&quot; class=&quot;post-general-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We study prediction of future outcomes with supervised models that use privileged information during learning. The privileged information comprises samples of time series observed between the baseline time of prediction and the future outcome; this information is only available at training time which differs from the traditional supervised learning. Our question is when using this privileged data leads to more sample-efficient learning of models that use only baseline data for predictions at test time. We give an algorithm for this setting and prove that when the time series are drawn from a non-stationary Gaussian-linear dynamical system of fixed horizon, learning with privileged information is more efficient than learning without it. On synthetic data, we test the limits of our algorithm and theory, both when our assumptions hold and when they are violated. On three diverse real-world datasets, we show that our approach is generally preferable to classical learning, particularly when data is scarce. Finally, we relate our estimator to a distillation approach both theoretically and empirically.&lt;/p&gt;</content><author><name>Rickard Karlsson, Martin Willbo, Zeshan Hussain, Rahul G. Krishnan, David Sontag, Fredrik Johansson</name></author><category term="blog" /><summary type="html">Abstract</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/posts/lupi_illustration.png" /><media:content medium="image" url="http://localhost:4000/assets/posts/lupi_illustration.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Predicting progression &amp;amp; cognitive decline in amyloid-positive patients with Alzheimer’s disease</title><link href="http://localhost:4000/blog/2021/03/15/adni-prediction.html" rel="alternate" type="text/html" title="Predicting progression &amp;amp; cognitive decline in amyloid-positive patients with Alzheimer’s disease" /><published>2021-03-15T09:00:00+01:00</published><updated>2021-03-15T09:00:00+01:00</updated><id>http://localhost:4000/blog/2021/03/15/adni-prediction</id><content type="html" xml:base="http://localhost:4000/blog/2021/03/15/adni-prediction.html">&lt;h3 id=&quot;abstract&quot;&gt;Abstract&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/mmse_change.png&quot; alt=&quot;Change in MMSE over time&quot; class=&quot;post-general-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In Alzheimer’s disease, amyloid-β (Aβ) peptides aggregate in the brain forming CSF amyloid levels, which are a key pathological hallmark of the disease. However, CSF amyloid levels may also be present in cognitively unimpaired elderly individuals. Therefore, it is of great value to explain the variance in disease progression among patients with Aβ pathology. We studied the problem of predicting disease progression and cognitive decline of potential AD patients with established Aβ pathology using the Alzheimer’s Disease Neuroimaging Initiative (ADNI) database.
A cohort of n=2293 participants, of whom n=749 were Aβ positive, was selected from the to study heterogeneity in disease progression for individuals with Aβ pathology. Aβ pathology status was determined based on the Aβ42/Aβ40 ratio. Due to the relatively low prevalence of Aβ pathology, models fit only to Aβ-positive subjects were compared to models fit to an extended cohort including subjects without established Aβ pathology, adjusting for covariate differences between the cohorts.&lt;/p&gt;

&lt;p&gt;The best performing machine learning model achieved a performance of R2 = 0.388 predicting the change in MMSE scores two years after baseline using a linear regression model based on a cohort with weighted samples in the training cohort using all features at baseline. Similarly, a gradient boosting model with all subjects weighted equally predicted the change in diagnosis with high accuracy (F1 = 0.791) when using all features. For the most accurate predictions, our models combine variables measured at the baseline such as cognitive tests, CSF biomarkers, proteins and genetic markers. Among these, baseline cognitive tests scores were found to be the strongest predictors, accounting for most of the variance explained by all features, across models. Finally, we identified that even though the Aβ42/Aβ40 ratio is a good predictor for AD in the preclinical phase, the respective levels of Aβ are less useful in predicting progression among only Aβ-positive subjects. Baseline assessments of cognitive function accounts for the majority of variance explained in the prediction of two-year decline but is insufficient for achieving optimal results in longer-term predictions.&lt;/p&gt;</content><author><name>Hákon Valur Dansson, Lena Stempfle, Hildur Egilsdóttir, Alexander Schliep, Erik Portelius, Kaj Blennow, Henrik Zetterberg, Fredrik D Johansson</name></author><category term="blog" /><summary type="html">Abstract</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/posts/mmse_change.png" /><media:content medium="image" url="http://localhost:4000/assets/posts/mmse_change.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Learning to search efficiently for causally near-optimal treatments</title><link href="http://localhost:4000/blog/2020/12/31/policy-search.html" rel="alternate" type="text/html" title="Learning to search efficiently for causally near-optimal treatments" /><published>2020-12-31T09:00:00+01:00</published><updated>2020-12-31T09:00:00+01:00</updated><id>http://localhost:4000/blog/2020/12/31/policy-search</id><content type="html" xml:base="http://localhost:4000/blog/2020/12/31/policy-search.html">&lt;h3 id=&quot;abstract&quot;&gt;Abstract&lt;/h3&gt;
&lt;p&gt;Finding an effective medical treatment often requires a search by trial and error. Making this search more efficient by minimizing the number of unnecessary trials could lower both costs and patient suffering. We formalize this problem as learning a policy for finding a near-optimal treatment in a minimum number of trials using a causal inference framework. We give a model-based dynamic programming algorithm which learns from observational data while being robust to unmeasured confounding. To reduce time complexity, we suggest a greedy algorithm which bounds the near-optimality constraint. The methods are evaluated on synthetic and real-world healthcare data and compared to model-free reinforcement learning. We find that our methods compare favorably to the model-free baseline while offering a more transparent trade-off between search time and treatment efficacy.&lt;/p&gt;</content><author><name>Fredrik Johansson</name></author><category term="blog" /><summary type="html">Abstract Finding an effective medical treatment often requires a search by trial and error. Making this search more efficient by minimizing the number of unnecessary trials could lower both costs and patient suffering. We formalize this problem as learning a policy for finding a near-optimal treatment in a minimum number of trials using a causal inference framework. We give a model-based dynamic programming algorithm which learns from observational data while being robust to unmeasured confounding. To reduce time complexity, we suggest a greedy algorithm which bounds the near-optimality constraint. The methods are evaluated on synthetic and real-world healthcare data and compared to model-free reinforcement learning. We find that our methods compare favorably to the model-free baseline while offering a more transparent trade-off between search time and treatment efficacy.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/posts/policy_search_timeline.png" /><media:content medium="image" url="http://localhost:4000/assets/posts/policy_search_timeline.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">A new group: The Healthy AI lab!</title><link href="http://localhost:4000/blog/2020/09/01/new-students.html" rel="alternate" type="text/html" title="A new group: The Healthy AI lab!" /><published>2020-09-01T10:00:00+02:00</published><updated>2020-09-01T10:00:00+02:00</updated><id>http://localhost:4000/blog/2020/09/01/new-students</id><content type="html" xml:base="http://localhost:4000/blog/2020/09/01/new-students.html">&lt;p&gt;As of September 2020, the division of Data Science &amp;amp; AI have four brand new PhD students with Fredrik Johansson as main advisor. This marks the start of the Healthy AI lab at Chalmers University of Technology. Adam Breitholtz, Newton Mwai, Lena Stempfle and Anton Matsson begin their doctoral studies, funded by the Wallenberg AI, Autonomous Systems and Software programme. We conduct research into machine learning for decision making and causal inference with applications in healthcare.&lt;/p&gt;</content><author><name>Fredrik Johansson</name></author><category term="blog" /><summary type="html">As of September 2020, the division of Data Science &amp;amp; AI have four brand new PhD students with Fredrik Johansson as main advisor. This marks the start of the Healthy AI lab at Chalmers University of Technology. Adam Breitholtz, Newton Mwai, Lena Stempfle and Anton Matsson begin their doctoral studies, funded by the Wallenberg AI, Autonomous Systems and Software programme. We conduct research into machine learning for decision making and causal inference with applications in healthcare.</summary></entry></feed>