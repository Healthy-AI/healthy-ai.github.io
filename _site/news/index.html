<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>News | Healthy AI Lab</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="News" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Healthy AI lab: Research in machine learning and healthcare" />
<meta property="og:description" content="Healthy AI lab: Research in machine learning and healthcare" />
<link rel="canonical" href="http://localhost:4000/news/" />
<meta property="og:url" content="http://localhost:4000/news/" />
<meta property="og:site_name" content="Healthy AI Lab" />
<script type="application/ld+json">
{"headline":"News","url":"http://localhost:4000/news/","description":"Healthy AI lab: Research in machine learning and healthcare","@type":"WebPage","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Healthy AI Lab" /></head>
<body><header class="site-header" role="banner">
  <div class="wrapper"><div class="site-title">
      <a rel="author" href="/">Healthy AI Lab<br/></a>
      <div class="site-subtitle">at Chalmers University of Technology</div>
    </div>

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
      <label for="nav-trigger">
        <span class="menu-icon">
          <svg viewBox="0 0 18 15" width="18px" height="15px">
            <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
          </svg>
        </span>
      </label>

      <div class="trigger"><a class="page-link" href="/about/">About</a><a class="page-link" href="/code/">Code &amp; data</a><a class="page-link" href="/news/">News</a><a class="page-link" href="/people/">People</a></div>
    </nav>

  </div>
</header>
<main class="page-content" aria-label="Content">    
      

<div class="wrapper">
    <header class="post-header">
      <h1 class="post-title">News</h1>
    </header>

    <ul class="post-list home-post-list">
        
          <li>
            <div class="post-list-description">
                <h3>
                  <a class="post-link" href="/blog/2022/07/27/cbope.html">
                    Case-Based Off-Policy Evaluation Using Prototype Learning
                  </a>
                </h3>
                <h4>Jul 27, 2022</h4>
                
                  <div class="post-list-image">
                    <img src="/assets/posts/cbope.png" />
                  </div>
                
                
                  Importance sampling (IS) is often used to perform off-policy evaluation but it is prone to several issues---especially when the behavior policy is unknown and must be estimated from data. Significant differences between target and behavior policies can result in uncertain value estimates due to, for example, high variance. Standard practices such as inspecting IS weights may be insufficient to diagnose such problems and determine for which type of inputs the policies differ in suggested actions and resulting values. To address this, we propose estimating the behavior policy for IS using prototype learning. The learned prototypes provide a condensed summary of the input-action space, which allows for describing differences between policies and assessing the support for evaluating a certain target policy. In addition, we can describe a value estimate in terms of prototypes to understand which parts of the target policy have the most impact on the estimate. We find that this provides new insights in the examination of a learned policy for sepsis management. Moreover, we study the bias resulting from restricting models to use prototypes, how bias propagates to IS weights and estimated values and how this varies with history length.
                
            </div>
          </li>
          <li>
        
          <li>
            <div class="post-list-description">
                <h3>
                  <a class="post-link" href="/blog/2022/06/22/spsm.html">
                    Sharing pattern submodels for prediction with missing values
                  </a>
                </h3>
                <h4>Jun 22, 2022</h4>
                
                  <div class="post-list-image">
                    <img src="/assets/posts/SPSM_Example_graphic_final.png" />
                  </div>
                
                
                  Missing values are unavoidable in many applications of machine learning and present a challenge both during training and at test time. When variables are missing in recurring patterns, fitting separate pattern submodels have been proposed as a solution. However, independent models do not make efficient use of all available data. Conversely, fitting a shared model to the full data set typically relies on imputation which may be suboptimal when missingness depends on unobserved factors. We propose an alternative approach, called sharing pattern submodels, which make predictions that are a) robust to missing values at test time, b) maintains or improves the predictive power of pattern submodels, and c) has a short description enabling improved interpretability. We identify cases where sharing is provably optimal, even when missingness itself is predictive and when the prediction target depends on unobserved variables. Classification and regression experiments on synthetic data and two healthcare data sets demonstrate that our models achieve a favorable trade-off between pattern specialization and information sharing.
                
            </div>
          </li>
          <li>
        
          <li>
            <div class="post-list-description">
                <h3>
                  <a class="post-link" href="/blog/2022/04/07/adcb.html">
                    ADCB: An Alzheimer’s disease simulator for benchmarking observational estimators of causal effects
                  </a>
                </h3>
                <h4>Apr 7, 2022</h4>
                
                  <div class="post-list-image">
                    <img src="/assets/posts/causal_graph_color-crop.png" />
                  </div>
                
                
                  Simulators make unique benchmarks for causal effect estimation as they do not rely on unverifiable assumptions or the ability to intervene on real-world systems. This is especially important for estimators targeting healthcare applications as possibilities for experimentation are limited with good reason. We develop a simulator of clinical variables associated with Alzheimer’s disease, aimed to serve as a benchmark for causal effect estimation while modeling intricacies of healthcare data. We fit the system to the Alzheimer’s Disease Neuroimaging Initiative (ADNI) dataset and ground hand-crafted components in results from comparative treatment trials and observational treatment patterns. The simulator includes parameters which alter the nature and difficulty of the causal inference tasks, such as latent variables, effect heterogeneity, length of observed subject history, behavior policy and sample size. We use the simulator to compare standard estimators of average and conditional treatment effects.
                
            </div>
          </li>
          <li>
        
          <li>
            <div class="post-list-description">
                <h3>
                  <a class="post-link" href="/blog/2022/02/01/lupi-linear.html">
                    Learning using privileged time series information
                  </a>
                </h3>
                <h4>Feb 1, 2022</h4>
                
                  <div class="post-list-image">
                    <img src="/assets/posts/lupi_illustration.png" />
                  </div>
                
                
                  We study prediction of future outcomes with supervised models that use privileged information during learning. The privileged information comprises samples of time series observed between the baseline time of prediction and the future outcome; this information is only available at training time which differs from the traditional supervised learning. Our question is when using this privileged data leads to more sample-efficient learning of models that use only baseline data for predictions at test time. We give an algorithm for this setting and prove that when the time series are drawn from a non-stationary Gaussian-linear dynamical system of fixed horizon, learning with privileged information is more efficient than learning without it. On synthetic data, we test the limits of our algorithm and theory, both when our assumptions hold and when they are violated. On three diverse real-world datasets, we show that our approach is generally preferable to classical learning, particularly when data is scarce. Finally, we relate our estimator to a distillation approach both theoretically and empirically.
                
            </div>
          </li>
          <li>
        
          <li>
            <div class="post-list-description">
                <h3>
                  <a class="post-link" href="/blog/2021/03/15/adni-prediction.html">
                    Predicting progression &amp; cognitive decline in amyloid-positive patients with Alzheimer&#39;s disease
                  </a>
                </h3>
                <h4>Mar 15, 2021</h4>
                
                  <div class="post-list-image">
                    <img src="/assets/posts/mmse_change.png" />
                  </div>
                
                
                  In Alzheimer’s disease, amyloid-β (Aβ) peptides aggregate in the brain forming CSF amyloid levels, which are a key pathological hallmark of the disease. However, CSF amyloid levels may also be present in cognitively unimpaired elderly individuals. Therefore, it is of great value to explain the variance in disease progression among patients with Aβ pathology. We studied the problem of predicting disease progression and cognitive decline of potential AD patients with established Aβ pathology using the Alzheimer’s Disease Neuroimaging Initiative (ADNI) database.
                
            </div>
          </li>
          <li>
        
          <li>
            <div class="post-list-description">
                <h3>
                  <a class="post-link" href="/blog/2020/12/31/policy-search.html">
                    Learning to search efficiently for causally near-optimal treatments
                  </a>
                </h3>
                <h4>Dec 31, 2020</h4>
                
                  <div class="post-list-image">
                    <img src="/assets/posts/policy_search_timeline.png" />
                  </div>
                
                
                  Finding an effective medical treatment often requires a search by trial and error. Making this search more efficient by minimizing the number of unnecessary trials could lower both costs and patient suffering. We formalize this problem as learning a policy for finding a near-optimal treatment in a minimum number of trials using a causal inference framework. We give a model-based dynamic programming algorithm which learns from observational data while being robust to unmeasured confounding. To reduce time complexity, we suggest a greedy algorithm which bounds the near-optimality constraint. The methods are evaluated on synthetic and real-world healthcare data and compared to model-free reinforcement learning. We find that our methods compare favorably to the model-free baseline while offering a more transparent trade-off between search time and treatment efficacy.
                
            </div>
          </li>
          <li>
        
          <li>
            <div class="post-list-description">
                <h3>
                  <a class="post-link" href="/blog/2020/09/01/new-students.html">
                    A new group: The Healthy AI lab!
                  </a>
                </h3>
                <h4>Sep 1, 2020</h4>
                
                
                  As of September 2020, the division of Data Science & AI have four brand new PhD students with Fredrik Johansson as main advisor. This marks the start of the Healthy AI lab at Chalmers University of Technology. Adam Breitholtz, Newton Mwai, Lena Stempfle and Anton Matsson begin their doctoral studies, funded by the Wallenberg AI, Autonomous Systems and Software programme.
                
            </div>
          </li>
          <li></ul>
</div>

    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <!--<h2 class="footer-heading">Healthy AI Lab</h2>-->

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <!---->
        <!--
        <ul class="contact-list"><li>Contact:</li>
          <li><a class="u-email" href="mailto:fredrik.johansson@chalmers.se">fredrik.johansson@chalmers.se</a></li></ul>-->
      </div>

      <div class="footer-col footer-col-2">

      </div>
    </div>

  </div>

</footer>
</body>

</html>
